{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4781ed32",
   "metadata": {},
   "source": [
    "# Import necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf518b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "from IPython.display import Image\n",
    "\n",
    "from lime import explanation\n",
    "from lime import lime_base\n",
    "\n",
    "import pickle5 as pickle\n",
    "import onnx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c08eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime_timeseries import LimeTimeSeriesExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c801856",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3a6ce",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585687ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class a_dataset(object):\n",
    "    def __init__(self):\n",
    "        self.X = list()\n",
    "        self.Y = list()\n",
    "        self.parents = list()\n",
    "dataset = a_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b28aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to = './data/dataset.pkl'\n",
    "with open(path_to, 'rb') as inp:\n",
    "    dataset.__dict__ = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b68cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X = np.array(dataset.X)\n",
    "dataset.Y = np.array(dataset.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2379dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroT = True\n",
    "zeroE = True\n",
    "\n",
    "plt.figure()\n",
    "for idx in range(len(dataset.Y)):\n",
    "    if dataset.Y[idx,0] == 0 and dataset.Y[idx,1] != 0 and zeroT:\n",
    "        plt.plot(dataset.X[idx,:],label=r'$\\Delta T = 0 $',color='tab:blue'); zeroT = False\n",
    "    elif dataset.Y[idx,1] == 0 and zeroE:\n",
    "        plt.plot(dataset.X[idx,:], label=r'$\\Delta \\mu \\varepsilon = 0$',color='tab:orange'); zeroE = False\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc703f98",
   "metadata": {},
   "source": [
    "### Split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8af2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_per = 0.6\n",
    "train_per = 0.2\n",
    "val_per = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37452842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array with idxs\n",
    "idx_compleate = np.linspace( 0, dataset.X.shape[0]-1, dataset.X.shape[0] )\n",
    "\n",
    "# Generate training index\n",
    "idx_train, idx_tv = train_test_split(\n",
    "    idx_compleate, \n",
    "    test_size=(1-train_per),\n",
    "    random_state=1\n",
    ")\n",
    "# Generate test and validation index\n",
    "idx_val, idx_test = train_test_split(\n",
    "    idx_tv, \n",
    "    test_size = test_per/(test_per+val_per),\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "idx_train = idx_train.astype(int)\n",
    "idx_val = idx_val.astype(int)\n",
    "idx_test = idx_test.astype(int)\n",
    "\n",
    "Xdict = dict.fromkeys(['train', 'val', 'test'])\n",
    "Ydict = dict.fromkeys(['train', 'val', 'test'])\n",
    "\n",
    "Xdict['train'] = dataset.X[idx_train,:]\n",
    "Ydict['train'] = dataset.Y[idx_train,:]\n",
    "Xdict['val'] = dataset.X[idx_val,:]\n",
    "Ydict['val'] = dataset.Y[idx_val,:]\n",
    "Xdict['test'] = dataset.X[idx_test,:]\n",
    "Ydict['test'] = dataset.Y[idx_test,:]\n",
    "\n",
    "dataset.X = Xdict\n",
    "dataset.Y = Ydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28ba73",
   "metadata": {},
   "source": [
    "### Set up scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0bcfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class a_scaler(object):\n",
    "    def __init__(self,X=None):\n",
    "        if not X is None:\n",
    "            self.max = np.zeros(X.shape[1])\n",
    "            self.min = np.zeros(X.shape[1])\n",
    "            print('Creating scaler for',X.shape[1],'items and',X.shape[0],'samples')\n",
    "            for i in range(X.shape[1]):\n",
    "                self.max[i] = np.amax(X[:,i])\n",
    "                self.min[i] = np.amin(X[:,i])\n",
    "                if self.max[i] == self.min[i]:\n",
    "                    print('Column',i,'with single value')\n",
    "                    self.max[i] = np.amax(X[:,i])*2\n",
    "                    self.min[i] = 0\n",
    "                    \n",
    "    def transform(self,x):\n",
    "\n",
    "        if isinstance(x,list):\n",
    "            x = np.array(x)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(1,-1)\n",
    "\n",
    "        out = np.empty_like(x)\n",
    "        for i in range(x.shape[1]):\n",
    "            out[:,i] = (x[:,i]-self.min[i])/(self.max[i]-self.min[i])\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self,z):\n",
    "\n",
    "        if isinstance(z,list):\n",
    "            z = np.array(z)\n",
    "        if len(z.shape) == 1:\n",
    "            z = z.reshape(1,-1)\n",
    "\n",
    "        out = np.empty_like(z)\n",
    "        for i in range(z.shape[1]):\n",
    "            out[:,i] = (self.max[i]-self.min[i]) * z[:,i] + self.min[i]\n",
    "        return out\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7894c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoadScalers = True\n",
    "if LoadScalers:\n",
    "    scalerX = a_scaler()\n",
    "    scalerY = a_scaler()\n",
    "    \n",
    "    path_to = './data/scalerY.pkl'\n",
    "    with open(path_to, 'rb') as inp:\n",
    "        scalerY.__dict__ = pickle.load(inp)\n",
    "    path_to = './data/scalerX.pkl'\n",
    "    with open(path_to, 'rb') as inp:\n",
    "        scalerX.__dict__ = pickle.load(inp)\n",
    "else:\n",
    "    scalerX = a_scaler(dataset.X['train'])\n",
    "    scalerY = a_scaler(dataset.Y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e34f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dataset.X.keys():\n",
    "    dataset.X[key] = scalerX.transform(dataset.X[key])\n",
    "    dataset.Y[key] = scalerX.transform(dataset.Y[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ff2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dataset.X['test'][0,:],color='tab:blue');\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87be79f",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a846d8",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "306b8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Weights initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "# Compress sensor layer\n",
    "class First_Stage_Layer(nn.Module):\n",
    "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Layer secuence\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(12001, 6000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6000, 3000),\n",
    "            nn.Tanh(),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Linear(3000, 1500),\n",
    "            nn.Tanh(),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Linear(1500, 750),\n",
    "            nn.Tanh(),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Linear(750, 375)\n",
    "        ).apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        x = self.FC(x)\n",
    "        return x\n",
    "\n",
    "class Second_Stage_Layer(nn.Module):\n",
    "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layer secuence\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(375, 350),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(350, 300),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(300, 250),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(250, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 150),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(150, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(25, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.ReLU()\n",
    "        ).apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        x = self.FC(x)\n",
    "        return x\n",
    "\n",
    "class TE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TE, self).__init__()\n",
    "        self.cs0 = First_Stage_Layer()\n",
    "        self.fc_T = Second_Stage_Layer()\n",
    "        self.fc_E = Second_Stage_Layer()\n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x0 = self.cs0(x.reshape(bs,-1))\n",
    "\n",
    "        T = self.fc_T(x0).flatten()\n",
    "        E = self.fc_E(x0).flatten()\n",
    "\n",
    "        return T, E\n",
    "\n",
    "class TE_single(nn.Module):\n",
    "    def __init__(self,TE,n):\n",
    "        super(TE_single, self).__init__()\n",
    "        self.TE = TE\n",
    "        self.n = n\n",
    "        for p in self.TE.parameters():\n",
    "            p.requires_grad=False\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        y = self.TE(x.reshape(bs,-1))\n",
    "        y = y[self.n]\n",
    "        return y\n",
    "    \n",
    "    def proba(self,x):\n",
    "        bs = x.shape[0]\n",
    "        x = torch.from_numpy(x.reshape(bs,-1)).float()\n",
    "        self.TE.eval()\n",
    "        y = self.TE(x)\n",
    "        y = y[self.n]\n",
    "        y = y.numpy()\n",
    "        y = y.reshape(bs,-1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baade56",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e77bf7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_model = TE()\n",
    "pre_model.load_state_dict(torch.load(\"./data/model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c34b5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TE_single(pre_model,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd689748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9990])\n"
     ]
    }
   ],
   "source": [
    "input = torch.from_numpy( np.array([dataset.X['test'][-1]]) ).float()\n",
    "model.eval()\n",
    "y = model(input)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fd9e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7293267 ]\n",
      " [0.98490435]\n",
      " [0.25388497]]\n"
     ]
    }
   ],
   "source": [
    "y = model.proba(np.array([dataset.X['test'][11,:],dataset.X['test'][13,:],dataset.X['test'][12,:]]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868d794",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f4f7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 11 # explained instance\n",
    "num_features = 12 # how many feature contained in explanation\n",
    "num_slices = 120 # split time series\n",
    "series = dataset.X['test'][idx,:]\n",
    "plt.plot(series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3be4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/temis/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/temis/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "explainer = LimeTimeSeriesExplainer()\n",
    "exp = explainer.explain_instance(series, model.proba,labels=(0,), num_features=num_features, num_samples=500, num_slices=num_slices)\n",
    "exp.as_pyplot_figure(label=0)\n",
    "plt.title('')\n",
    "plt.xlabel(r'$\\Delta T$ (normalized)')\n",
    "plt.ylabel('Slice\\nindex',labelpad = 20).set_rotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177e254",
   "metadata": {},
   "source": [
    "### Split signal in its parts for a pretty plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "533ba7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = scalerX.inverse_transform(series.reshape(1,-1))[0]\n",
    "sk = [r'$P_1 \\star P_1$',\n",
    "        r'$P_1 \\star P_2$',\n",
    "        r'$P_2 \\star P_2$',\n",
    "        r'$S_1 \\star S_1$',\n",
    "        r'$S_1 \\star S_2$',\n",
    "        r'$S_2 \\star S_2$',\n",
    "        r'$\\Delta \\nu$']\n",
    "signal = dict.fromkeys(sk)\n",
    "\n",
    "signal[sk[0]] = [np.linspace(0,2000,2000) ,sp[0:2000]]\n",
    "signal[sk[1]] = [np.linspace(2000,4000,2000) ,sp[2000:4000]]\n",
    "signal[sk[2]] = [np.linspace(4000,6000,2000) ,sp[4000:6000]]\n",
    "signal[sk[3]] = [np.linspace(6000,8000,2000) ,sp[6000:8000]]\n",
    "signal[sk[4]] = [np.linspace(8000,10000,2000) ,sp[8000:10000]]\n",
    "signal[sk[5]] = [np.linspace(10000,12000,2000) ,sp[10000:12000]]\n",
    "signal[sk[6]] = [12001 ,sp[12000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "275335d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for key, val in signal.items():\n",
    "    plt.plot(val[0],val[1],label=key) if 'nu' not in key else None\n",
    "plt.scatter(signal[sk[6]][0],signal[sk[6]][1],label=sk[6], color='tab:pink')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "393101cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_per_slice = math.ceil(len(series) / num_slices)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for key, val in signal.items():\n",
    "    plt.plot(val[0],val[1],label=key)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "max_weight = 0\n",
    "for i in range(num_features):\n",
    "    feature, weight = exp.as_list(label=0)[i]\n",
    "    if weight > max_weight:\n",
    "        max_weight = weight\n",
    "\n",
    "for i in range(num_features):\n",
    "    feature, weight = exp.as_list(label=0)[i]\n",
    "    start = feature * values_per_slice\n",
    "    end = start + values_per_slice\n",
    "    color = 'red' if weight < 0 else 'green' \n",
    "    plt.axvspan(start , end, color=color, alpha=abs(weight*0.6/max_weight))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e45be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
